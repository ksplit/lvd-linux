module kernel {
rpc projection ret_workqueue_struct* alloc<{{}}, {{(DEFAULT_GFP_FLAGS)}}>(caller) __alloc_workqueue_key( char*  fmt, unsigned int  flags, int  max_active, projection key* [unused] key, char* [unused] lock_name ) {
	projection < struct workqueue_struct > ret_workqueue_struct {
	}
	projection < struct lock_class_key > key {
	}
}
rpc int  __bitmap_weight( long unsigned int* [in] bitmap, unsigned int  bits ) {
}
rpc int  __pci_register_driver( projection _global_pci_driver* [in] drv, projection owner*  owner, char*  mod_name ) {
	projection < struct pci_device_id > pci_driver_id_table {
	}
	projection < struct module > owner {
	}
}
rpc void  __raw_spin_lock_init( projection lock* [in] lock, char* [unused] name, projection key* [unused] key ) {
	projection < struct raw_spinlock > lock {
	}
	projection < struct lock_class_key > key {
	}
}
rpc void  _dev_info( projection dev* [in] dev, char*  fmt ) {
	projection < struct device > dev {
		char* [in] init_name;
		projection device_bus_type* bus;
		projection device_device_driver* driver;
		projection device_class* class;
	}
	projection < struct bus_type > device_bus {
	}
	projection < struct device_driver > device_driver {
	}
	projection < struct class > device_class {
	}
}
rpc void  _raw_spin_unlock( projection lock* [in] lock ) {
	projection < struct raw_spinlock > lock {
	}
}
rpc void  _raw_spin_unlock_irq( projection lock* [in] lock ) {
	projection < struct raw_spinlock > lock {
	}
}
rpc void  blk_cleanup_queue( projection q* [in] q ) {
	projection < struct request_queue > q {
		long unsigned int [in] queue_flags;
	}
}
rpc void  blk_execute_rq_nowait( projection q* [in] q, projection bd_disk*  bd_disk, projection rq* [in] rq, int  at_head, rpc_ptr  done done ) {
	projection < struct request_queue > q {
		long unsigned int [in] queue_flags;
	}
	projection < struct gendisk > bd_disk {
	}
	projection < struct request > rq {
		projection request_request_queue* q;
		unsigned int [in] cmd_type;
		long long unsigned int [in][out] cmd_flags;
		unsigned int [in][out] __data_len;
		long unsigned int [in][out] __sector;
		projection request_bio* bio;
		projection request_gendisk* rq_disk;
		long unsigned int [in] start_time;
		int [in][out] errors;
	}
	projection < struct request_queue > request_q {
	}
	projection < struct bio > request_bio {
	}
	projection < struct gendisk > request_rq_disk {
	}
}
rpc bool  blk_get_queue( projection q* [in] q ) {
	projection < struct request_queue > q {
		long unsigned int [in] queue_flags;
	}
}
rpc int  blk_mq_alloc_tag_set( projection set* [in] set ) {
	projection < struct blk_mq_tag_set > set {
		projection _global_blk_mq_ops* ops;
		unsigned int [in][out] nr_hw_queues;
		unsigned int [in][out] queue_depth;
		unsigned int [in] cmd_size;
		int [in] numa_node;
		void* [in] driver_data;
		projection _blk_mq_tags** tags;
	}
	projection < struct blk_mq_tags > blk_mq_tag_set_tags {
	}
}
rpc void  blk_mq_complete_request( projection rq* [in][out] rq, int  error ) {
	projection < struct request > rq {
		projection request_request_queue* q;
		unsigned int [in] cmd_type;
		long long unsigned int [in][out] cmd_flags;
		unsigned int [in][out] __data_len;
		long unsigned int [in][out] __sector;
		projection request_bio* bio;
		projection request_gendisk* rq_disk;
		long unsigned int [in] start_time;
		int [in][out] tag;
		int [in][out] errors;
	}
	projection < struct request_queue > request_q {
	}
	projection < struct bio > request_bio {
	}
	projection < struct gendisk > request_rq_disk {
	}
}
rpc void  blk_mq_end_request( projection rq* [in][out] rq, int  error ) {
	projection < struct request > rq {
		projection request_request_queue* q;
		unsigned int [in] cmd_type;
		long long unsigned int [in][out] cmd_flags;
		unsigned int [in][out] __data_len;
		long unsigned int [in][out] __sector;
		projection request_bio* bio;
		projection request_gendisk* rq_disk;
		long unsigned int [in] start_time;
		int [in][out] tag;
		int [out] errors;
	}
	projection < struct request_queue > request_q {
	}
	projection < struct bio > request_bio {
	}
	projection < struct gendisk > request_rq_disk {
	}
}
rpc void  blk_mq_free_request( projection rq* [in][out] rq ) {
	projection < struct request > rq {
		projection request_request_queue* q;
		long long unsigned int [in][out] cmd_flags;
		int [in][out] tag;
	}
	projection < struct request_queue > request_q {
	}
}
rpc void  blk_mq_free_tag_set( projection set* [in] set ) {
	projection < struct blk_mq_tag_set > set {
		projection _global_blk_mq_ops* ops;
		void* [in] driver_data;
		projection _blk_mq_tags** tags;
	}
	projection < struct blk_mq_tags > blk_mq_tag_set_tags {
	}
}
rpc projection ret_request_queue*  blk_mq_init_queue( projection set* [in] set ) {
	projection < struct request_queue > ret_request_queue {
	}
	projection < struct blk_mq_tag_set > set {
		projection _global_blk_mq_ops* ops;
		unsigned int [in] nr_hw_queues;
		unsigned int [in] queue_depth;
		int [in] numa_node;
		unsigned int [in] timeout;
		unsigned int [in][out] flags;
		void* [in] driver_data;
		projection _blk_mq_tags** tags;
	}
	projection < struct blk_mq_tags > blk_mq_tag_set_tags {
	}
}
rpc_ptr projection ret_blk_mq_hw_ctx*  blk_mq_ops_map_queue( projection q* [in] q, int  cpu ) {
	projection < struct blk_mq_hw_ctx > ret_blk_mq_hw_ctx {
	}
	projection < struct request_queue > q {
	}
}
rpc void  blk_mq_start_request( projection rq* [in] rq ) {
	projection < struct request > rq {
		projection request_request_queue* q;
		unsigned int [in] __data_len;
		unsigned short [in][out] nr_phys_segments;
	}
	projection < struct request_queue > request_q {
	}
}
rpc void  blk_mq_start_stopped_hw_queues( projection q* [in] q, bool  async ) {
	projection < struct request_queue > q {
	}
}
rpc void  blk_mq_stop_hw_queues( projection q* [in] q ) {
	projection < struct request_queue > q {
	}
}
rpc void  blk_mq_tagset_busy_iter( projection tagset* [in] tagset, rpc_ptr  fn fn, void*  priv ) {
	projection < struct blk_mq_tag_set > tagset {
		projection _global_blk_mq_ops* ops;
		unsigned int [in] nr_hw_queues;
		projection _blk_mq_tags** tags;
	}
	projection < struct blk_mq_tags > blk_mq_tag_set_tags {
	}
}
rpc void  blk_mq_update_nr_hw_queues( projection set* [in] set, int  nr_hw_queues ) {
	projection < struct blk_mq_tag_set > set {
		projection _global_blk_mq_ops* ops;
		unsigned int [in][out] nr_hw_queues;
		void* [in] driver_data;
		projection _blk_mq_tags** tags;
	}
	projection < struct blk_mq_tags > blk_mq_tag_set_tags {
	}
}
rpc void  blk_put_queue( projection q* [in] q ) {
	projection < struct request_queue > q {
	}
}
rpc int  blk_rq_count_integrity_sg( projection q* [in] q, projection bio* [in] bio ) {
	projection < struct request_queue > q {
	}
	projection < struct bio > bio {
	}
}
rpc int  blk_rq_map_integrity_sg( projection q* [in] q, projection bio* [in] bio, projection sglist* [in] sglist ) {
	projection < struct request_queue > q {
	}
	projection < struct bio > bio {
	}
	projection < struct scatterlist > sglist {
		long unsigned int [in][out] page_link;
		unsigned int [out] offset;
		unsigned int [in][out] length;
	}
}
rpc void  complete( projection x* [in] x ) {
	projection < struct completion > x {
		unsigned int [in][out] done;
		__wait_queue_head [in] wait;
	}
}
rpc int  del_timer_sync( projection timer* [in] timer ) {
	projection < struct timer_list > timer {
	}
}
rpc void  destroy_workqueue( projection wq* [in] wq ) {
	projection < struct workqueue_struct > wq {
	}
}
rpc void  device_release_driver( projection dev* [in] dev ) {
	projection < struct device > dev {
		projection device_device_private* p;
		projection device_bus_type* bus;
		projection device_device_driver* driver;
		void* [out] driver_data;
		projection device_dev_pm_domain* pm_domain;
	}
	projection < struct device_private > device_p {
	}
	projection < struct bus_type > device_bus {
	}
	projection < struct device_driver > device_driver {
	}
	projection < struct dev_pm_domain > device_pm_domain {
	}
}
rpc bool  flush_work( projection work* [in][out] work ) {
		projection < struct list_head> list_head {
			projection list_head_list_head* next;
		}
	projection < struct work_struct > work {
		atomic64_t [in][out] data;
		projection list_head entry;
	}
	projection < struct list_head > list_head_next {
	}
}
rpc void  free_irq( unsigned int  irq, void*  dev_id ) {
}
rpc projection ret_device*  get_device( projection dev* [in] dev ) {
	projection < struct device > ret_device {
	}
	projection < struct device > dev {
	}
}
rpc void  init_timer_key( projection timer* [in] timer, unsigned int  flags, char*  name, projection key*  key ) {
	projection < struct timer_list > timer {
	}
	projection < struct lock_class_key > key {
	}
}
rpc void* [ioremap(caller)]   ioremap_nocache( long long unsigned int  phys_addr, long unsigned int  size ) {
}
rpc void*  ioremap_wc( long long unsigned int  phys_addr, long unsigned int  size ) {
}
rpc int  irq_set_affinity_hint( unsigned int  irq, projection m* [in] m ) {
	projection < struct cpumask > m {
		array< long unsigned int, 1> [in] bits;
	}
}
rpc void*  kmalloc_order( long unsigned int  size, unsigned int  flags, unsigned int  order ) {
}
rpc int  mod_timer( projection timer* [in][out] timer, long unsigned int  expires ) {
	projection < struct timer_list > timer {
	}
}
rpc_ptr void  blk_mq_ops_exit_hctx( projection hctx* [in] hctx, unsigned int [unused] hctx_idx ) {
	projection < struct blk_mq_hw_ctx > hctx {
	}
}
rpc_ptr int  blk_mq_ops_init_hctx( projection hctx* [in] hctx, void*  data, unsigned int  hctx_idx ) {
	projection < struct blk_mq_hw_ctx > hctx {
		projection blk_mq_hw_ctx_blk_mq_tags* tags;
	}
	projection < struct blk_mq_tags > blk_mq_hw_ctx_tags {
	}
}
rpc_ptr int  blk_mq_ops_init_request( void*  data, projection req* [in] req, unsigned int [unused] hctx_idx, unsigned int [unused] rq_idx, unsigned int [unused] numa_node ) {
	projection < struct request > req {
	}
}
rpc projection ret_request*  nvme_alloc_request( projection q* [in] q, projection cmd* [in] cmd, unsigned int  flags, int  qid ) {
	projection < struct request > ret_request {
		unsigned int [out] cmd_type;
		long long unsigned int [in][out] cmd_flags;
	}
	projection < struct request_queue > q {
		long unsigned int [in] queue_flags;
	}
	projection < struct nvme_command > cmd {
	}
}
rpc void  nvme_cancel_request( projection req* [in][out] req, void*  data, bool [unused] reserved ) {
	projection < struct request > req {
		projection request_request_queue* q;
		unsigned int [in] cmd_type;
		long long unsigned int [in][out] cmd_flags;
		unsigned int [in][out] __data_len;
		long unsigned int [in][out] __sector;
		projection request_bio* bio;
		projection request_gendisk* rq_disk;
		long unsigned int [in] start_time;
		int [in][out] tag;
		int [in][out] errors;
	}
	projection < struct request_queue > request_q {
	}
	projection < struct bio > request_bio {
	}
	projection < struct gendisk > request_rq_disk {
	}
}
rpc bool  nvme_change_ctrl_state( projection ctrl* [in] ctrl, unsigned int  new_state ) {
	projection < struct nvme_ctrl > ctrl {
		unsigned int [in][out] state;
	}
}
rpc void  nvme_complete_async_event( projection ctrl* [in] ctrl, projection cqe* [in] cqe ) {
	projection < struct nvme_ctrl > ctrl {
		projection nvme_ctrl_device* device;
	}
	projection < struct device > nvme_ctrl_device {
	}
	projection < struct nvme_completion > cqe {
		unsigned short [in] status;
	}
}
rpc_ptr void  blk_mq_ops_complete( projection req* [in] req ) {
	projection < struct request > req {
		unsigned int [in] cmd_type;
		long long unsigned int [in] cmd_flags;
		long unsigned int [in] start_time;
		int [in] errors;
		unsigned int [in] timeout;
	}
}
rpc int  nvme_disable_ctrl( projection ctrl* [in] ctrl, long long unsigned int  cap ) {
	projection < struct nvme_ctrl > ctrl {
		projection nvme_ctrl_blk_mq_tag_set* tagset;
		projection nvme_ctrl_device* device;
		unsigned int [in][out] ctrl_config;
	}
	projection < struct blk_mq_tag_set > nvme_ctrl_tagset {
	}
	projection < struct device > nvme_ctrl_device {
	}
}
rpc int  nvme_enable_ctrl( projection ctrl* [in] ctrl, long long unsigned int  cap ) {
	projection < struct nvme_ctrl > ctrl {
		projection nvme_ctrl_device* device;
		unsigned int [in][out] ctrl_config;
		unsigned int [out] page_size;
	}
	projection < struct device > nvme_ctrl_device {
	}
}
rpc_ptr unsigned int  pci_error_handlers_error_detected( projection pdev* [in] pdev, unsigned int  state ) {
	projection < struct pci_dev > pdev {
	}
}
rpc_ptr void  pci_error_handlers_resume( projection pdev* [in] pdev ) {
	projection < struct pci_dev > pdev {
	}
}
rpc int  nvme_init_ctrl( projection ctrl* [in] ctrl, projection dev*  dev, projection ops*  ops, long unsigned int  quirks ) {
		projection < struct kref> kref {
			atomic_t [in] refcount;
		}
	projection < struct nvme_ctrl > ctrl {
		unsigned int [out] state;
		projection kref kref;
		int [in][out] instance;
		projection nvme_ctrl_device* device;
	}
	projection < struct device > nvme_ctrl_device {
	}
	projection < struct device > dev {
	}
	projection < struct nvme_ctrl_ops > ops {
	}
}
rpc int  nvme_init_hctx( projection hctx* [in] hctx, void*  data, unsigned int  hctx_idx ) {
	projection < struct blk_mq_hw_ctx > hctx {
		projection blk_mq_hw_ctx_blk_mq_tags* tags;
	}
	projection < struct blk_mq_tags > blk_mq_hw_ctx_tags {
	}
}
rpc int  nvme_init_identify( projection ctrl* [in] ctrl ) {
	projection < struct nvme_ctrl > ctrl {
		projection nvme_ctrl_request_queue* admin_q;
		projection nvme_ctrl_device* device;
		atomic_t [in] abort_limit;
	}
	projection < struct request_queue > nvme_ctrl_admin_q {
	}
	projection < struct device > nvme_ctrl_device {
	}
}
rpc int  nvme_init_request( void*  data, projection req* [in] req, unsigned int  hctx_idx, unsigned int [unused] rq_idx, unsigned int [unused] numa_node ) {
	projection < struct request > req {
	}
}
rpc void  nvme_kill_queues( projection ctrl* [in] ctrl ) {
	projection < struct nvme_ctrl > ctrl {
	}
}
rpc_ptr int  pci_driver_sriov_configure( projection pdev* [in] pdev, int  numvfs ) {
	projection < struct pci_dev > pdev {
	}
}
rpc_ptr int  blk_mq_ops_poll( projection hctx* [in] hctx, unsigned int  tag ) {
	projection < struct blk_mq_hw_ctx > hctx {
	}
}
rpc_ptr int  pci_driver_probe( projection pdev* [in] pdev, projection id* [in] id ) {
	projection < struct pci_dev > pdev {
	}
	projection < struct pci_device_id > id {
		long unsigned int [in] driver_data;
	}
}
rpc void  nvme_put_ctrl( projection ctrl* [in] ctrl ) {
		projection < struct kref> kref {
			atomic_t [in] refcount;
		}
	projection < struct nvme_ctrl > ctrl {
		projection kref kref;
	}
}
rpc void  nvme_queue_async_events( projection ctrl* [in] ctrl ) {
	projection < struct nvme_ctrl > ctrl {
	}
}
rpc_ptr int  blk_mq_ops_queue_rq( projection hctx* [in] hctx, projection bd* [in] bd ) {
	projection < struct blk_mq_hw_ctx > hctx {
		projection blk_mq_hw_ctx_request_queue* queue;
	}
	projection < struct request_queue > blk_mq_hw_ctx_queue {
	}
	projection < struct blk_mq_queue_data > bd {
		projection blk_mq_queue_data_request* rq;
	}
	projection < struct request > blk_mq_queue_data_rq {
	}
}
rpc void  nvme_queue_scan( projection ctrl* [in] ctrl ) {
	projection < struct nvme_ctrl > ctrl {
		unsigned int [in] state;
	}
}
rpc_ptr void  pci_driver_remove( projection pdev* [in] pdev ) {
	projection < struct pci_dev > pdev {
	}
}
rpc void  nvme_remove_namespaces( projection ctrl* [in] ctrl ) {
	projection < struct nvme_ctrl > ctrl {
		unsigned int [in] state;
	}
}
rpc void  nvme_requeue_req( projection req* [in] req ) {
	projection < struct request > req {
		projection request_request_queue* q;
		long long unsigned int [in][out] cmd_flags;
		unsigned int [in] __data_len;
		unsigned short [in][out] nr_phys_segments;
	}
	projection < struct request_queue > request_q {
	}
}
rpc_ptr void  pci_error_handlers_reset_notify( projection pdev* [in] pdev, bool  prepare ) {
	projection < struct pci_dev > pdev {
	}
}
rpc int  nvme_set_queue_count( projection ctrl* [in] ctrl, int* [in][out] count ) {
	projection < struct nvme_ctrl > ctrl {
		projection nvme_ctrl_request_queue* admin_q;
	}
	projection < struct request_queue > nvme_ctrl_admin_q {
	}
}
rpc int  nvme_setup_cmd( projection ns* [in] ns, projection req* [in] req, projection cmd* [in][out] cmd ) {
	projection < struct nvme_ns > ns {
		int [in] lba_shift;
		unsigned short [in] ms;
		unsigned char [in] pi_type;
	}
	projection < struct request > req {
		unsigned int [in] cmd_type;
		long long unsigned int [in] cmd_flags;
		unsigned int [in][out] __data_len;
		long unsigned int [in] __sector;
		projection request_bio* bio;
		unsigned short [out] nr_phys_segments;
		int [in] tag;
	}
	projection < struct bio > request_bio {
	}
	projection < struct nvme_command > cmd {
	}
}
rpc_ptr void  pci_driver_shutdown( projection pdev* [in] pdev ) {
	projection < struct pci_dev > pdev {
	}
}
rpc int  nvme_shutdown_ctrl( projection ctrl* [in] ctrl ) {
	projection < struct nvme_ctrl > ctrl {
		projection nvme_ctrl_device* device;
		unsigned int [in][out] ctrl_config;
	}
	projection < struct device > nvme_ctrl_device {
	}
}
rpc_ptr unsigned int  pci_error_handlers_slot_reset( projection pdev* [in] pdev ) {
	projection < struct pci_dev > pdev {
	}
}
rpc void  nvme_start_queues( projection ctrl* [in] ctrl ) {
	projection < struct nvme_ctrl > ctrl {
	}
}
rpc void  nvme_stop_queues( projection ctrl* [in] ctrl ) {
	projection < struct nvme_ctrl > ctrl {
	}
}
rpc int  nvme_submit_sync_cmd( projection q* [in] q, projection cmd*  cmd, void*  buffer, unsigned int  bufflen ) {
	projection < struct request_queue > q {
		long unsigned int [in] queue_flags;
	}
	projection < struct nvme_command > cmd {
	}
}
rpc_ptr unsigned int  blk_mq_ops_timeout( projection req* [in] req, bool [unused] reserved ) {
	projection < struct request > req {
		int [in] tag;
		int [out] errors;
	}
}
rpc void  nvme_uninit_ctrl( projection ctrl* [in] ctrl ) {
	projection < struct nvme_ctrl > ctrl {
		unsigned int [in] state;
		int [in] instance;
	}
}
rpc int  pci_cleanup_aer_uncorrect_error_status( projection dev* [in] dev ) {
	projection < struct pci_dev > dev {
	}
}
rpc bool  pci_device_is_present( projection pdev* [in] pdev ) {
	projection < struct pci_dev > pdev {
	}
}
rpc void  pci_disable_device( projection dev* [in] dev ) {
	projection < struct pci_dev > dev {
		atomic_t [in] enable_cnt;
	}
}
rpc void  pci_disable_msi( projection dev* [in] dev ) {
		projection < struct device> device {
			projection list_head msi_list;
		}
			projection < struct list_head> list_head {
				projection list_head_list_head* next;
			}
	projection < struct pci_dev > dev {
		projection device dev;
		unsigned int [out] irq;
		unsigned int [in] msi_enabled : 1;
	}
	projection < struct list_head > list_head_next {
	}
}
rpc void  pci_disable_msix( projection dev* [in] dev ) {
		projection < struct device> device {
			projection list_head msi_list;
		}
			projection < struct list_head> list_head {
				projection list_head_list_head* next;
			}
	projection < struct pci_dev > dev {
		projection device dev;
		unsigned int [in] msix_enabled : 1;
	}
	projection < struct list_head > list_head_next {
	}
}
rpc int  pci_disable_pcie_error_reporting( projection dev* [in] dev ) {
	projection < struct pci_dev > dev {
	}
}
rpc int  pci_enable_device_mem( projection dev* [in] dev ) {
	projection < struct pci_dev > dev {
		array< resource, 11> [in] resource;
		unsigned int [in] msi_enabled : 1;
		unsigned int [in] msix_enabled : 1;
		atomic_t [in] enable_cnt;
	}
}
rpc int  pci_enable_msi_range( projection dev* [in] dev, int  minvec, int  maxvec ) {
	projection < struct pci_dev > dev {
		unsigned int [in] msi_enabled : 1;
		unsigned int [in] msix_enabled : 1;
	}
}
rpc int  pci_enable_msix( projection dev* [in] dev, projection entries* [in] entries, int  nvec ) {
	projection < struct pci_dev > dev {
		unsigned int [in] msi_enabled : 1;
		unsigned int [in] msix_enabled : 1;
	}
	projection < struct msix_entry > entries {
	}
}
rpc int  pci_enable_msix_range( projection dev* [in] dev, projection entries* [in] entries, int  minvec, int  maxvec ) {
	projection < struct pci_dev > dev {
		unsigned int [in] msi_enabled : 1;
		unsigned int [in] msix_enabled : 1;
	}
	projection < struct msix_entry > entries {
	}
}
rpc int  pci_enable_pcie_error_reporting( projection dev* [in] dev ) {
	projection < struct pci_dev > dev {
	}
}
rpc void  pci_release_selected_regions( projection pdev* [in] pdev, int  bars ) {
	projection < struct pci_dev > pdev {
		array< resource, 11> [in] resource;
	}
}
rpc int  pci_request_selected_regions( projection pdev* [in] pdev, int  bars, char*  res_name ) {
	projection < struct pci_dev > pdev {
		array< resource, 11> [in] resource;
	}
}
rpc void  pci_restore_state( projection dev* [in] dev ) {
		projection < struct device> device {
			projection list_head msi_list;
		}
			projection < struct list_head> list_head {
				projection list_head_list_head* next;
			}
	projection < struct pci_dev > dev {
		projection device dev;
		unsigned int [in] irq;
		unsigned int [in] msi_enabled : 1;
		unsigned int [in] msix_enabled : 1;
	}
	projection < struct list_head > list_head_next {
	}
}
rpc int  pci_save_state( projection dev* [in] dev ) {
	projection < struct pci_dev > dev {
	}
}
rpc int  pci_select_bars( projection dev* [in] dev, long unsigned int  flags ) {
	projection < struct pci_dev > dev {
		array< resource, 11> [in] resource;
	}
}
rpc void  pci_set_master( projection dev* [in] dev ) {
	projection < struct pci_dev > dev {
	}
}
rpc void  pci_unregister_driver( projection _global_pci_driver* [in][out] drv ) {
	projection < struct pci_device_id > pci_driver_id_table {
	}
}
rpc void  put_device( projection dev* [in] dev ) {
	projection < struct device > dev {
	}
}
rpc bool  queue_work_on( int  cpu, projection wq* [in] wq, projection work* [in][out] work ) {
	projection < struct workqueue_struct > wq {
	}
	projection < struct work_struct > work {
		atomic64_t [in][out] data;
	}
}
rpc int  request_threaded_irq( unsigned int  irq, rpc_ptr  handler handler, rpc_ptr  thread_fn thread_fn, long unsigned int  irqflags, char*  devname, void*  dev_id ) {
}
rpc long unsigned int  round_jiffies( long unsigned int  j ) {
}
rpc long unsigned int  wait_for_completion_io_timeout( projection x* [in][out] x, long unsigned int [in][out] timeout ) {
	projection < struct completion > x {
		unsigned int [in][out] done;
		__wait_queue_head [in][out] wait;
	}
}
rpc unsigned int  work_busy( projection work* [in] work ) {
	projection < struct work_struct > work {
		atomic64_t [in] data;
	}
}
rpc projection ret_blk_mq_hw_ctx*  blk_mq_map_queue( projection q* [in] q, int  cpu ) {
	projection < struct blk_mq_hw_ctx > ret_blk_mq_hw_ctx {
	}
	projection < struct request_queue > q {
	}
}
projection < struct blk_mq_ops > _global_blk_mq_ops {
	rpc_ptr blk_mq_ops_complete complete;
	rpc_ptr blk_mq_ops_exit_hctx exit_hctx;
	rpc_ptr blk_mq_ops_init_hctx init_hctx;
	rpc_ptr blk_mq_ops_init_request init_request;
	rpc_ptr blk_mq_ops_map_queue map_queue;
	rpc_ptr blk_mq_ops_poll poll;
	rpc_ptr blk_mq_ops_queue_rq queue_rq;
	rpc_ptr blk_mq_ops_timeout timeout;
}
projection < struct pci_driver > _global_pci_driver {
	array<pci_device_id*, null> id_table;
	char* [in] name;
	projection _global_pci_error_handlers* err_handler;
	rpc_ptr pci_driver_probe probe;
	rpc_ptr pci_driver_remove remove;
	rpc_ptr pci_driver_shutdown shutdown;
	rpc_ptr pci_driver_sriov_configure sriov_configure;
}
projection < struct pci_error_handlers > _global_pci_error_handlers {
	rpc_ptr pci_error_handlers_error_detected error_detected;
	rpc_ptr pci_error_handlers_reset_notify reset_notify;
	rpc_ptr pci_error_handlers_resume resume;
	rpc_ptr pci_error_handlers_slot_reset slot_reset;
}


}